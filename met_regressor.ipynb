{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7Q77n6SqIpcF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ground features: [NETRAD,\tRg,\tH,\tLE,\tG,\tu,\tTa_max,\tTa_min,\tTa_mean,\tTc_max,\tTc_min,\tTc_mean,\tVPD_max,\tVPD_min,\tVPD_mean,\tRH_mean,\tPa]\n",
        "\n",
        "Unused Features: DATE, YEAR\n",
        "\n",
        "Predicting: ET"
      ],
      "metadata": {
        "id": "ZSQL20pHJORk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "//\n",
        "\n",
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "N4HqCxQxPY6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "df = pd.read_csv('OLA_daily_2021.csv') \n",
        "df1 = pd.read_csv('OLA_daily_2022.csv')\n",
        "df2 = pd.read_csv('VAC_daily_2022.csv')\n",
        "df3 = pd.read_csv('VAC_daily_2022.csv')\n",
        "df4 = pd.read_csv('WWF_daily_2021.csv')\n",
        "df5 = pd.read_csv('WWF_daily_2022.csv')\n",
        "\n",
        "df = pd.concat([df, df1, df2, df3, df4, df5])\n",
        "\n",
        "# drop unused columns\n",
        "df = df.drop(columns='DATE')\n",
        "df = df.drop(columns='YEAR')\n",
        "df = df.dropna()\n",
        "\n",
        "df = df[df.ET != -9999]\n",
        "df = df[df.NETRAD != -9999]\n",
        "df = df[df.Rg != -9999]\n",
        "df = df[df.H != -9999]\n",
        "df = df[df.LE != -9999]\n",
        "df = df[df.G != -9999]\n",
        "df = df[df.u != -9999]\n",
        "df = df[df.Ta_max != -9999]\n",
        "df = df[df.Ta_min != -9999]\n",
        "df = df[df.Ta_mean != -9999]\n",
        "df = df[df.Tc_max != -9999]\n",
        "df = df[df.Tc_min != -9999]\n",
        "df = df[df.Tc_mean != -9999]\n",
        "df = df[df.VPD_max != -9999]\n",
        "df = df[df.VPD_min != -9999]\n",
        "df = df[df.VPD_mean != -9999]\n",
        "df = df[df.RH_mean != -9999]\n",
        "df = df[df.Pa != -9999]\n",
        "\n",
        "# make X, y sets\n",
        "y = df['ET']\n",
        "X = df.drop(labels=['ET'], axis=1)\n",
        "    \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25)\n",
        "\n",
        "# scale features to be in [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# train and fit only from training data\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "F0N2sHG3JGvR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generic SciKit-Learn RandomForest Regression Model"
      ],
      "metadata": {
        "id": "4dm3Tgm6Pw-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from numpy import mean\n",
        "\n",
        "scores = []\n",
        "for random_state in range(50):\n",
        "  regr = RandomForestRegressor(max_depth=10, random_state=0, max_features='sqrt', bootstrap=True)\n",
        "  regr.fit(X_train, y_train)\n",
        "\n",
        "  #y_pred = regr.predict(X_test)\n",
        "  scores.append(regr.score(X_test, y_test))\n",
        "print(\"Averaged for 50 random seeds...\")\n",
        "print(\"Generic model R^2 score: (-inf, 1], with 1 being highest fit score possible.\")\n",
        "print(mean(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X99C5tBPP7YJ",
        "outputId": "3fda68c5-1652-4a8b-f5bc-a97a6f9fd4ef"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged for 50 random seeds...\n",
            "Generic model R^2 score: (-inf, 1], with 1 being highest fit score possible.\n",
            "0.9638641625808247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning: RandomSearch"
      ],
      "metadata": {
        "id": "x4Rv330UX7hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['none', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 150, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "test_regr = RandomForestRegressor()\n",
        "clf = RandomizedSearchCV(estimator=test_regr, param_distributions=random_grid, n_iter=1000, cv=None, verbose=2, random_state=99)\n",
        "search = clf.fit(X_train, y_train)\n",
        "print(search.best_params_)\n"
      ],
      "metadata": {
        "id": "V6hmB-9_X6oo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}